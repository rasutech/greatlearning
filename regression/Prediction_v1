def main(app_name, db_params, excel_path):
    """Main execution function"""
    try:
        # Connect to database
        conn = connect_to_db(db_params)
        
        # Load outage data
        print("Loading outage data...")
        outage_df = load_outage_data(excel_path)
        outage_df = outage_df[outage_df['app_name'] == app_name]
        
        if len(outage_df) == 0:
            raise ValueError(f"No outage data found for app: {app_name}")
        
        # Load alerts data
        print("Loading alerts data...")
        start_date = outage_df['opened'].min() - timedelta(days=1)
        end_date = outage_df['outage_end_time'].max()
        alerts_df = load_alerts_data(conn, app_name, start_date, end_date)
        
        # Create feature matrix
        print("Creating feature matrix...")
        X, y = create_feature_matrix(alerts_df, outage_df)
        
        # Analyze missing data
        missing_stats = pd.DataFrame({
            'missing_count': X.isnull().sum(),
            'missing_percentage': (X.isnull().sum() / len(X) * 100).round(2)
        })
        missing_stats = missing_stats[missing_stats['missing_count'] > 0]
        print("\nMissing Data Analysis:")
        print(missing_stats)
        
        # Preprocess features
        print("\nPreprocessing features...")
        X_processed, preprocessor, feature_names = preprocess_features(X)
        
        # Train model and get results
        print("\nTraining model...")
        model_results = train_model_with_pca(X_processed, y)
        
        # Analyze feature importance
        print("\nAnalyzing feature importance...")
        feature_importance = analyze_feature_importance(
            model_results['model'],
            model_results['pca'],
            feature_names
        )
        
        # Generate report
        print("\nGenerating report...")
        generate_report(
            app_name=app_name,
            data_shape=X.shape,
            model_results=model_results,
            feature_importance=feature_importance,
            missing_stats=missing_stats
        )
        
        # Close database connection
        conn.close()
        
        print("\nAnalysis completed successfully!")
        
        return {
            'model_results': model_results,
            'feature_importance': feature_importance,
            'preprocessor': preprocessor,
            'feature_names': feature_names
        }
        
    except Exception as e:
        print(f"Error in analysis pipeline: {str(e)}")
        import traceback
        print(traceback.format_exc())
        if 'conn' in locals():
            conn.close()
        raise

if __name__ == "__main__":
    # Configuration
    db_params = {
        "dbname": "your_database",
        "user": "your_username",
        "password": "your_password",
        "host": "your_host",
        "port": "your_port"
    }
    
    # Example usage
    app_name = "YOUR_APP_NAME"
    excel_path = "path_to_your_outage_data.xlsx"
    
    try:
        # Run the analysis
        results = main(app_name, db_params, excel_path)
        
        # Print summary metrics
        print("\nSummary Metrics:")
        print(f"ROC-AUC Score: {results['model_results']['roc_auc']:.4f}")
        print("\nTop 5 Important Features:")
        for feature, importance in list(results['feature_importance']['top_features'].items())[:5]:
            print(f"{feature}: {importance:.4f}")
            
    except Exception as e:
        print(f"Error running analysis: {str(e)}")

# Function to make predictions on new data
def predict_outage_probability(new_data, model_results, preprocessor, feature_names):
    """
    Make predictions on new data using the trained model
    
    Parameters:
    new_data : DataFrame containing new alert data
    model_results : dict containing trained model and PCA
    preprocessor : fitted preprocessor
    feature_names : list of feature names
    
    Returns:
    Array of probabilities for outage prediction
    """
    try:
        # Preprocess new data
        X_new = preprocessor.transform(new_data)
        
        # Apply PCA transformation
        X_new_pca = model_results['pca'].transform(X_new)
        
        # Make predictions
        probabilities = model_results['model'].predict_proba(X_new_pca)[:, 1]
        
        return probabilities
        
    except Exception as e:
        print(f"Error making predictions: {str(e)}")
        raise

# Example usage of prediction function
def example_prediction():
    """Example of how to use the prediction function"""
    # Create sample new data
    sample_data = pd.DataFrame({
        'total_alerts': [5],
        'datasource_Newrelic': [2],
        'datasource_Prometheus': [3],
        'priority_critical': [1],
        'priority_warning': [4]
    })
    
    try:
        # Load saved model and preprocessor (you would need to save these first)
        # This is just an example - you would need to implement model saving/loading
        loaded_results = {
            'model': saved_model,
            'pca': saved_pca
        }
        loaded_preprocessor = saved_preprocessor
        loaded_feature_names = saved_feature_names
        
        # Make prediction
        probabilities = predict_outage_probability(
            sample_data,
            loaded_results,
            loaded_preprocessor,
            loaded_feature_names
        )
        
        print(f"Predicted outage probability: {probabilities[0]:.4f}")
        
    except Exception as e:
        print(f"Error in example prediction: {str(e)}")

# Optional: Add model persistence
def save_model(model_results, preprocessor, feature_names, filename_prefix):
    """Save model and associated objects"""
    from joblib import dump
    try:
        # Save model objects
        dump(model_results['model'], f'{filename_prefix}_model.joblib')
        dump(model_results['pca'], f'{filename_prefix}_pca.joblib')
        dump(preprocessor, f'{filename_prefix}_preprocessor.joblib')
        
        # Save feature names
        with open(f'{filename_prefix}_feature_names.txt', 'w') as f:
            f.write('\n'.join(feature_names))
            
        print("Model and associated objects saved successfully")
        
    except Exception as e:
        print(f"Error saving model: {str(e)}")
        raise

def load_model(filename_prefix):
    """Load saved model and associated objects"""
    from joblib import load
    try:
        # Load model objects
        model = load(f'{filename_prefix}_model.joblib')
        pca = load(f'{filename_prefix}_pca.joblib')
        preprocessor = load(f'{filename_prefix}_preprocessor.joblib')
        
        # Load feature names
        with open(f'{filename_prefix}_feature_names.txt', 'r') as f:
            feature_names = f.read().splitlines()
            
        return {
            'model': model,
            'pca': pca,
            'preprocessor': preprocessor,
            'feature_names': feature_names
        }
        
    except Exception as e:
        print(f"Error loading model: {str(e)}")
        raise
